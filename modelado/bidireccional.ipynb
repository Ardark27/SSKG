{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "def load_json(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = load_json(r'corpus\\papers_with_code_somef\\1903.10583v1\\felipelouza_bwsd.json')\n",
    "# corpus\\papers_with_code_somef\\1903.10583v1\\felipelouza_gsa-is_.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = load_json(r'../pdf_info_extractor\\data_somef\\10.1007_978-3-319-68204-4_9\\dgarijo_Widoco_.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def easy_doi_finder(data:dict):\n",
    "    try:\n",
    "        doi = data['result']['doi']\n",
    "        return doi\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_excerpt_parser(cite_list: list):\n",
    "    # remove @ and {}\n",
    "    cite_list = [element.replace('@', '').replace('{', '').replace('}', '') for element in cite_list]\n",
    "    # strip elements\n",
    "    cite_list = [element.strip() for element in cite_list]\n",
    "    # remove empty elements\n",
    "    cite_list = [element for element in cite_list if element != '']\n",
    "    # remove final comma\n",
    "    cite_list = [element[:-1] if element[-1] == ',' else element for element in cite_list]\n",
    "    \n",
    "    parsed_dict = {}\n",
    "    for element in cite_list:\n",
    "            if element.count('=') == 1:\n",
    "                try:\n",
    "                    key, value = element.split('=')\n",
    "                    key = key.strip()\n",
    "                    value = value.strip()\n",
    "                except ValueError:\n",
    "                    key = element.split('=')[0].strip()\n",
    "                    value = ''\n",
    "                parsed_dict[key] = value\n",
    "    \n",
    "    return parsed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cff_parser(cite_list: list):\n",
    "    '''\n",
    "    Parse the citation list of a cff file given by somef\n",
    "    '''\n",
    "    # replace \" by ''\n",
    "    cite_list = [element.replace('\"', '') for element in cite_list]\n",
    "    # remove empty elements\n",
    "    cite_list = [element for element in cite_list if element != '']\n",
    "    \n",
    "    parsed_dict = {}\n",
    "    for element in cite_list:\n",
    "        if element.count(':') > 1:\n",
    "            key = element.split(':')[0].strip()\n",
    "            value = ':'.join(element.split(':')[1:]).strip()\n",
    "            parsed_dict[key] = value\n",
    "        else:\n",
    "            try:\n",
    "                key, value = element.split(':')\n",
    "                key = key.strip()\n",
    "                value = value.strip()\n",
    "            except ValueError:\n",
    "                key = element.split(':')[0].strip()\n",
    "                value = ''\n",
    "            parsed_dict[key] = value\n",
    "    return parsed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bibtex_parser(cite_list: list):\n",
    "    '''\n",
    "    Parse the citation list of a bibtex ref given by somef\n",
    "    '''\n",
    "    # parse first element\n",
    "    cite_list[0] = cite_list[0].replace('{','=')\n",
    "    # remove @ and {}\n",
    "    cite_list = [element.replace('@', '').replace('{', '').replace('}', '') for element in cite_list]\n",
    "    # strip elements\n",
    "    cite_list = [element.strip() for element in cite_list]\n",
    "    # remove empty elements\n",
    "    cite_list = [element for element in cite_list if element != '']\n",
    "    # remove final comma\n",
    "    cite_list = [element[:-1] if element[-1] == ',' else element for element in cite_list]\n",
    "    parsed_dict = {}\n",
    "    for element in cite_list:\n",
    "        if element.count('=') > 1:\n",
    "            key = element.split('=')[0].strip()\n",
    "            value = '='.join(element.split('=')[1:])\n",
    "            parsed_dict[key] = value\n",
    "        else:\n",
    "            try:\n",
    "                key, value = element.split('=')\n",
    "                key = key.strip()\n",
    "                value = value.strip()\n",
    "            except ValueError:\n",
    "                key = element.split('=')[0].strip()\n",
    "                value = ''\n",
    "            parsed_dict[key] = value\n",
    "    return parsed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3 = load_json(r'corpus/papers_with_code_somef\\2204.08775v3\\JuliaPlots_Plots.jl.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_doi(somef_data: dict):\n",
    "    '''\n",
    "    Find the doi in somef data \n",
    "    '''\n",
    "    try:\n",
    "        data = somef_data['citation']\n",
    "    except KeyError:\n",
    "        return False\n",
    "        \n",
    "    for cite in data:\n",
    "        try:\n",
    "            if cite['result']['format'] == 'cff':\n",
    "                cff = cff_parser(cite['result']['value'].split('\\n'))\n",
    "                doi_find = cff['doi'].replace('https://doi.org/','').replace('10.48550/arxiv.','').replace('10.48550/ARXIV.','').replace('/','_')\n",
    "                return doi_find,1\n",
    "            elif cite['result']['format'] == 'bibtex':\n",
    "                bibtex = bibtex_parser(cite['result']['value'].split('\\n'))\n",
    "                doi_find = bibtex['doi'].replace('https://doi.org/','').replace('10.48550/arxiv.','').replace('10.48550/ARXIV.','').replace('/','_')\n",
    "                return doi_find,2\n",
    "            elif cite['result']['type'] == 'Text_excerpt':\n",
    "                text = text_excerpt_parser(cite['result']['value'].split('\\n'))\n",
    "                doi_find = text['doi'].replace('https://doi.org/','').replace('10.48550/arxiv.','').replace('10.48550/ARXIV.','').replace('/','_')\n",
    "                return doi_find,3\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2204.08775', 2)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_doi(data_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18a6b418ca989a304418b74e14b57df096d22507d5bd0d85ac6f17ef362aab2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
